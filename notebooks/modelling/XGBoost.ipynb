{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn import model_selection\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TOP5_FEATURES = ['net_acc_std', 'net_acc_max', 'EDA_tonic_mean', 'EDA_tonic_min',  'EDA_tonic_max', 'label']\n",
    "TOP10_FEATURES = [\n",
    "    \"net_acc_std\",\n",
    "    \"net_acc_max\",\n",
    "    \"EDA_tonic_mean\",\n",
    "    \"EDA_tonic_min\",\n",
    "    \"EDA_tonic_max\",\n",
    "    \"EDA_smna_mean\",\n",
    "    \"EDA_smna_std\",\n",
    "    \"EDA_smna_min\",\n",
    "    \"EDA_smna_max\",\n",
    "    \"EDA_phasic_min\",\n",
    "    \"label\"\n",
    "]\n",
    "TOP_EDA_FEATURES = [\"EDA_smna_mean\", \"EDA_phasic_min\", \"EDA_tonic_mean\", \"EDA_tonic_min\", \"EDA_tonic_max\", \"label\"]\n",
    "\n",
    "STRESS = {\n",
    "    0: \"amusement\", 1: \"baseline\", 2: \"stress\"\n",
    "}\n",
    "STRESS_MAP = {\n",
    "    1: 0,\n",
    "    2: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_name, features):\n",
    "    data = pd.read_csv(f'../../data/03_primary/{dataset_name}/combined_subjects.csv')\n",
    "    df = data.loc[:, data.columns.intersection(features)]\n",
    "    df = df[df.label != 0]\n",
    "    Y_ = df.label.map(STRESS_MAP)\n",
    "    X_ = df.drop(columns=['label'])\n",
    "    return model_selection.train_test_split(X_, Y_, test_size=0.25, random_state=42, stratify=Y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(m, dataset_name, features):\n",
    "    X, x, Y, y = prepare_dataset(dataset_name, features)\n",
    "    start_time = time.time()\n",
    "    result = m.fit(X, Y).predict(x)\n",
    "    print(f\"Finished in: {time.time() - start_time:.2f} seconds\")\n",
    "    print(\"Accuracy: {:.2f}%\".format(metrics.accuracy_score(y, result) * 100))\n",
    "    print(\"Balanced Accuracy: {:.2f}%\".format(metrics.balanced_accuracy_score(y, result) * 100))\n",
    "    print(\"F1 Score: {0:.2f}\".format(metrics.f1_score(y, result, average='macro')))\n",
    "    print(\"Precision: {0:.2f}\".format(metrics.precision_score(y, result, average='macro')))\n",
    "    print(\"Recall: {0:.2f}\".format(metrics.recall_score(y, result, average='macro')))\n",
    "    print(\"R2 Score: {0:.2f}\".format(metrics.r2_score(y, result)))\n",
    "\n",
    "    return m, X, x, Y, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in: 1.23 seconds\n",
      "Accuracy: 94.86%\n",
      "Balanced Accuracy: 94.69%\n",
      "F1 Score: 0.94\n",
      "Precision: 0.94\n",
      "Recall: 0.95\n",
      "R2 Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "train(xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42), 'WESAD_preprocessed_int10_add10', TOP5_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in: 0.43 seconds\n",
      "Accuracy: 95.60%\n",
      "Balanced Accuracy: 95.24%\n",
      "F1 Score: 0.95\n",
      "Precision: 0.95\n",
      "Recall: 0.95\n",
      "R2 Score: 0.81\n"
     ]
    }
   ],
   "source": [
    "train(xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42), 'WESAD_preprocessed_int10_add15', TOP5_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in: 0.10 seconds\n",
      "Accuracy: 96.82%\n",
      "Balanced Accuracy: 96.52%\n",
      "F1 Score: 0.97\n",
      "Precision: 0.97\n",
      "Recall: 0.97\n",
      "R2 Score: 0.86\n"
     ]
    }
   ],
   "source": [
    "train(xgb.XGBClassifier(objective=\"binary:logistic\", eta=0.1, random_state=42), 'WESAD_preprocessed_int15_add15', TOP5_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in: 0.16 seconds\n",
      "Accuracy: 98.41%\n",
      "Balanced Accuracy: 98.33%\n",
      "F1 Score: 0.98\n",
      "Precision: 0.98\n",
      "Recall: 0.98\n",
      "R2 Score: 0.93\n"
     ]
    }
   ],
   "source": [
    "top10_model, X_train, X_test, y_train, y_test = train(xgb.XGBClassifier(objective=\"binary:logistic\", eta=0.1, random_state=42), 'WESAD_preprocessed_int15_add15', TOP10_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished in: 0.10 seconds\n",
      "Accuracy: 97.27%\n",
      "Balanced Accuracy: 97.17%\n",
      "F1 Score: 0.97\n",
      "Precision: 0.97\n",
      "Recall: 0.97\n",
      "R2 Score: 0.88\n"
     ]
    }
   ],
   "source": [
    "train(xgb.XGBClassifier(objective=\"binary:logistic\", eta=0.1, random_state=42), 'WESAD_preprocessed_int15_add15', TOP_EDA_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import explainerdashboard as expdb\n",
    "from explainerdashboard import ExplainerDashboard, RegressionExplainer\n",
    "from explainerdashboard import InlineExplainer\n",
    "from explainerdashboard.custom import (ImportancesComposite,\n",
    "                                       IndividualPredictionsComposite,\n",
    "                                       WhatIfComposite,\n",
    "                                       ShapDependenceComposite,\n",
    "                                       ShapInteractionsComposite,\n",
    "                                       DecisionTreesComposite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating self.shap_explainer = shap.TreeExplainer(model)\n",
      "Building ExplainerDashboard..\n",
      "The explainer object has no decision_trees property. so setting decision_trees=False...\n",
      "Warning: calculating shap interaction values can be slow! Pass shap_interaction=False to remove interactions tab.\n",
      "Generating layout...\n",
      "Calculating shap values...\n",
      "Calculating predictions...\n",
      "Calculating residuals...\n",
      "Calculating absolute residuals...\n",
      "Warning: mean-absolute-percentage-error is very large (40941814794277.234), you can hide it from the metrics by passing parameter show_metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ratus\\anaconda3\\envs\\ex\\lib\\site-packages\\xgboost\\core.py:122: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating shap interaction values...\n",
      "Reminder: TreeShap computational complexity is O(TLD^2), where T is the number of trees, L is the maximum number of leaves in any tree and D the maximal depth of any tree. So reducing these will speed up the calculation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ratus\\anaconda3\\envs\\ex\\lib\\site-packages\\xgboost\\core.py:122: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: mean-absolute-percentage-error is very large (40941814794277.234), you can hide it from the metrics by passing parameter show_metrics...\n",
      "Warning: mean-absolute-percentage-error is very large (40941814794277.234), you can hide it from the metrics by passing parameter show_metrics...\n",
      "Calculating dependencies...\n",
      "Calculating importances...\n",
      "Reminder: you can store the explainer (including calculated dependencies) with explainer.dump('explainer.joblib') and reload with e.g. ClassifierExplainer.from_file('explainer.joblib')\n",
      "Registering callbacks...\n",
      "Starting ExplainerDashboard inline (terminate it with ExplainerDashboard.terminate(8039))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"800\"\n",
       "            src=\"http://127.0.0.1:8039/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1cf1740d490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ratus\\anaconda3\\envs\\ex\\lib\\site-packages\\xgboost\\core.py:122: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "c:\\Users\\ratus\\anaconda3\\envs\\ex\\lib\\site-packages\\xgboost\\core.py:122: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "c:\\Users\\ratus\\anaconda3\\envs\\ex\\lib\\site-packages\\xgboost\\core.py:122: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n",
      "c:\\Users\\ratus\\anaconda3\\envs\\ex\\lib\\site-packages\\xgboost\\core.py:122: UserWarning:\n",
      "\n",
      "ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explainer = RegressionExplainer(top10_model, X_test, y_test, model_output='logodds')\n",
    "\n",
    "ExplainerDashboard(explainer, mode='inline').run(8039)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a95701cbf4f370954074961b8bd4e4eec5bda27b020f956d4c8f963b594c21d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
