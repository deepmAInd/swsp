{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "title: WESAD Pre-processing\n",
    "author: deepmAInd (Dmitrii Ratusniuc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "In order to start the modelling phase, our team decided to modify the already existing preprocessing steps, so that final dataset is more suited for the needs of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext pretty_jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import scipy.signal as scisig\n",
    "import scipy.stats\n",
    "\n",
    "import cvxEDA\n",
    "\n",
    "import gc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Configurations\n",
       "In comparison to the original script, our version introduces sliding window with overlaps. This way we canhave more data points in the final dataset as well as probability of missing some important information is minimized. In this version, the following was changed:\n",
       "* Window length was increased to 45 seconds;\n",
       "* Interval was changed to 15 seconds."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%jmd\n",
    "\n",
    "# Configurations\n",
    "In comparison to the original script, our version introduces sliding window with overlaps. This way we canhave more data points in the final dataset as well as probability of missing some important information is minimized. In this version, the following was changed:\n",
    "* Window length was increased to 45 seconds;\n",
    "* Interval was changed to 15 seconds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -.-|m { input_fold: show }\n",
    "\n",
    "WINDOW_IN_SECONDS = 30\n",
    "WINDOW_ADDITION = 15\n",
    "WINDOW_INTERVAL = 15\n",
    "\n",
    "WINDOW_LENGTH = WINDOW_IN_SECONDS + WINDOW_ADDITION\n",
    "\n",
    "data_folder = \"../data\"\n",
    "INPUT_FOLDER = f\"../../RawData/WESAD\"\n",
    "OUTPUT_FOLDER = f\"{data_folder}/03_primary/WESAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Functions and Class Definition\n",
       "First, we set up global variables and constants."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%jmd\n",
    "\n",
    "# Functions and Class Definition\n",
    "First, we set up global variables and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# E4 (wrist) Sampling Frequencies\n",
    "fs_dict = {'ACC': 32, 'BVP': 64, 'EDA': 4, 'TEMP': 4, 'label': 700, 'Resp': 700}\n",
    "label_dict = {'baseline': 1, 'stress': 2, 'amusement': 0}\n",
    "int_to_label = {1: 'baseline', 2: 'stress', 0: 'amusement'}\n",
    "feat_names = None\n",
    "# savePath = 'data'\n",
    "subject_feature_path = '/subject_feats'\n",
    "\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "if not os.path.exists(OUTPUT_FOLDER + subject_feature_path):\n",
    "    os.makedirs(OUTPUT_FOLDER + subject_feature_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next, we create class to read and parse whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SubjectData:\n",
    "\n",
    "    def __init__(self, main_path, subject_number):\n",
    "        self.name = f'S{subject_number}'\n",
    "        self.subject_keys = ['signal', 'label', 'subject']\n",
    "        self.signal_keys = ['chest', 'wrist']\n",
    "        self.chest_keys = ['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']\n",
    "        self.wrist_keys = ['ACC', 'BVP', 'EDA', 'TEMP']\n",
    "        #with open(os.path.join(main_path, self.name) + '/' + self.name + '.pkl', 'rb') as file:\n",
    "        with open(main_path + '/' +  self.name + '/' + self.name + '.pkl', 'rb') as file:\n",
    "            self.data = pickle.load(file, encoding='latin1')\n",
    "        self.labels = self.data['label']\n",
    "\n",
    "    def get_wrist_data(self):\n",
    "        data = self.data['signal']['wrist']\n",
    "        data.update({'Resp': self.data['signal']['chest']['Resp']})\n",
    "        return data\n",
    "\n",
    "    def get_chest_data(self):\n",
    "        return self.data['signal']['chest']\n",
    "\n",
    "    def extract_features(self):  # only wrist\n",
    "        results = \\\n",
    "            {\n",
    "            key: get_statistics(self.get_wrist_data()[key].flatten(), self.labels, key)\n",
    "            for key in self.wrist_keys\n",
    "        }\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We define functions which help extracting various features out of EDA, Temperature and Acceleration data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eda_stats(y):\n",
    "    Fs = fs_dict['EDA']\n",
    "    yn = (y - y.mean()) / y.std()\n",
    "    [r, p, t, l, d, e, obj] = cvxEDA.cvxEDA(yn, 1. / Fs)\n",
    "    return [r, p, t, l, d, e, obj]\n",
    "\n",
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    # Filtering Helper functions\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = scisig.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    # Filtering Helper functions\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = scisig.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def get_slope(series):\n",
    "    linreg = scipy.stats.linregress(np.arange(len(series)), series )\n",
    "    slope = linreg[0]\n",
    "    return slope\n",
    "\n",
    "def get_window_stats(data, label=-1):\n",
    "    mean_features = np.mean(data)\n",
    "    std_features = np.std(data)\n",
    "    min_features = np.amin(data)\n",
    "    max_features = np.amax(data)\n",
    "\n",
    "    features = {'mean': mean_features, 'std': std_features, 'min': min_features, 'max': max_features,\n",
    "                'label': label}\n",
    "    return features\n",
    "\n",
    "def get_net_accel(data):\n",
    "    return (data['ACC_x'] ** 2 + data['ACC_y'] ** 2 + data['ACC_z'] ** 2).apply(lambda x: np.sqrt(x))\n",
    "\n",
    "def get_peak_freq(x):\n",
    "    f, Pxx = scisig.periodogram(x, fs=8)\n",
    "    psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "    peak_freq = psd_dict[max(psd_dict.keys())]\n",
    "    return peak_freq\n",
    "\n",
    "# https://github.com/MITMediaLabAffectiveComputing/eda-explorer/blob/master/AccelerometerFeatureExtractionScript.py\n",
    "def filterSignalFIR(eda, cutoff=0.4, numtaps=64):\n",
    "    f = cutoff / (fs_dict['ACC'] / 2.0)\n",
    "    FIR_coeff = scisig.firwin(numtaps, f)\n",
    "\n",
    "    return scisig.lfilter(FIR_coeff, 1, eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next code cell contains function which removes all non Emphatica4 data, keeps observations recorded only during three specific stages of the experiment and extracts new features out of collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_features(e4_data_dict, labels, norm_type=None):\n",
    "\n",
    "    # Dataframes for each sensor type\n",
    "    eda_df = pd.DataFrame(e4_data_dict['EDA'], columns=['EDA'])\n",
    "    bvp_df = pd.DataFrame(e4_data_dict['BVP'], columns=['BVP'])\n",
    "    acc_df = pd.DataFrame(e4_data_dict['ACC'], columns=['ACC_x', 'ACC_y', 'ACC_z'])\n",
    "    temp_df = pd.DataFrame(e4_data_dict['TEMP'], columns=['TEMP'])\n",
    "    label_df = pd.DataFrame(labels, columns=['label'])\n",
    "    resp_df = pd.DataFrame(e4_data_dict['Resp'], columns=['Resp'])\n",
    "\n",
    "    # Filter EDA\n",
    "    eda_df['EDA'] = butter_lowpass_filter(eda_df['EDA'], 1.0, fs_dict['EDA'], 6)\n",
    "\n",
    "    # Filter ACM\n",
    "    for _ in acc_df.columns:\n",
    "        acc_df[_] = filterSignalFIR(acc_df.values)\n",
    "\n",
    "    # Adding indices for combination due to differing sampling frequencies\n",
    "    eda_df.index = [(1 / fs_dict['EDA']) * i for i in range(len(eda_df))]\n",
    "    bvp_df.index = [(1 / fs_dict['BVP']) * i for i in range(len(bvp_df))]\n",
    "    acc_df.index = [(1 / fs_dict['ACC']) * i for i in range(len(acc_df))]\n",
    "    temp_df.index = [(1 / fs_dict['TEMP']) * i for i in range(len(temp_df))]\n",
    "    label_df.index = [(1 / fs_dict['label']) * i for i in range(len(label_df))]\n",
    "    resp_df.index = [(1 / fs_dict['Resp']) * i for i in range(len(resp_df))]\n",
    "    # print(eda_df)\n",
    "\n",
    "    # Change indices to datetime\n",
    "    eda_df.index = pd.to_datetime(eda_df.index, unit='s')\n",
    "    bvp_df.index = pd.to_datetime(bvp_df.index, unit='s')\n",
    "    temp_df.index = pd.to_datetime(temp_df.index, unit='s')\n",
    "    acc_df.index = pd.to_datetime(acc_df.index, unit='s')\n",
    "    label_df.index = pd.to_datetime(label_df.index, unit='s')\n",
    "    resp_df.index = pd.to_datetime(resp_df.index, unit='s')\n",
    "\n",
    "    # New EDA features\n",
    "    r, p, t, l, d, e, obj = eda_stats(eda_df['EDA'])\n",
    "    eda_df['EDA_phasic'] = r\n",
    "    eda_df['EDA_smna'] = p\n",
    "    eda_df['EDA_tonic'] = t\n",
    "\n",
    "    # Combined dataframe\n",
    "    df = eda_df.join(bvp_df, how='outer')\n",
    "    df = df.join(temp_df, how='outer')\n",
    "    df = df.join(acc_df, how='outer')\n",
    "    df = df.join(label_df, how='outer')\n",
    "\n",
    "    df['label'] = df['label'].fillna(method='bfill')\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df_ = df.drop(columns=['label'])\n",
    "    df_ = df_.dropna(how='all')\n",
    "\n",
    "    df_merged = df_.join(df['label'], how='left')\n",
    "\n",
    "    if norm_type == 'std':\n",
    "        # std norm\n",
    "        df_merged = (df_merged - df_merged.mean()) / df_merged.std()\n",
    "    elif norm_type == 'minmax':\n",
    "        # minmax norm\n",
    "        df_merged (df_merged - df_merged.min()) / (df_merged.max() - df_merged.min())\n",
    "\n",
    "    # Group by\n",
    "    grouped = df_merged.groupby('label')\n",
    "\n",
    "    baseline = grouped.get_group(1)\n",
    "    stress = grouped.get_group(2)\n",
    "    amusement = grouped.get_group(3)\n",
    "    return grouped, baseline, stress, amusement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following function generates combines collected data based on the defined window lengths and intervals between windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_samples(data, label):\n",
    "    global feat_names\n",
    "    global WINDOW_LENGTH\n",
    "    global WINDOW_INTERVAL\n",
    "\n",
    "    samples = []\n",
    "    # Using label freq (64 Hz) as our reference frequency due to it being the largest\n",
    "    # and thus encompassing the lesser ones in its resolution.\n",
    "    window_len = fs_dict['BVP'] * WINDOW_LENGTH\n",
    "    window_int = fs_dict['BVP'] * WINDOW_INTERVAL\n",
    "    i = 0\n",
    "    data.head()\n",
    "    while (window_int * i + window_len) < len(data):\n",
    "\n",
    "        # Get window of data\n",
    "        w = data[window_int * i : window_int * i + window_len]\n",
    "\n",
    "        # Add/Calc rms acc\n",
    "        # w['net_acc'] = get_net_accel(w)\n",
    "        w = pd.concat([w, get_net_accel(w)], names=['acc_net'])\n",
    "        #w.columns = ['net_acc', 'ACC_x', 'ACC_y', 'ACC_z', 'BVP',\n",
    "        #           'EDA', 'EDA_phasic', 'EDA_smna', 'EDA_tonic', 'TEMP',\n",
    "        #         'label']\n",
    "        # print(w.head())\n",
    "\n",
    "        cols = list(w.columns)\n",
    "        cols[0] = 'net_acc'\n",
    "        w.columns = cols\n",
    "\n",
    "        # Calculate stats for window\n",
    "        wstats = get_window_stats(data=w, label=label)\n",
    "\n",
    "        # Seperating sample and label\n",
    "        x = pd.DataFrame(wstats).drop('label', axis=0)\n",
    "        y = x['label'][0]\n",
    "        x.drop('label', axis=1, inplace=True)\n",
    "\n",
    "        if feat_names is None:\n",
    "            feat_names = []\n",
    "            for row in x.index:\n",
    "                for col in x.columns:\n",
    "                    feat_names.append('_'.join([str(row), str(col)]))\n",
    "\n",
    "        # sample df\n",
    "        wdf = pd.DataFrame(x.values.flatten()).T\n",
    "        wdf.columns = feat_names\n",
    "        wdf = pd.concat([wdf, pd.DataFrame({'label': y}, index=[0])], axis=1)\n",
    "\n",
    "        # More feats\n",
    "        wdf['BVP_peak_freq'] = get_peak_freq(w['BVP'].dropna())\n",
    "        wdf['TEMP_slope'] = get_slope(w['TEMP'].dropna())\n",
    "\n",
    "        samples.append(wdf)\n",
    "        i+=1\n",
    "\n",
    "    return pd.concat(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next function will pre-process data per subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_patient_data(subject_id):\n",
    "    global OUTPUT_FOLDER\n",
    "    global WINDOW_IN_SECONDS\n",
    "\n",
    "    # Make subject data object for Sx\n",
    "    subject = SubjectData(main_path=INPUT_FOLDER, subject_number=subject_id)\n",
    "\n",
    "    # Empatica E4 data - now with resp\n",
    "    e4_data_dict = subject.get_wrist_data()\n",
    "\n",
    "    # norm type\n",
    "    norm_type = None\n",
    "\n",
    "    # The 3 classes we are classifying\n",
    "    grouped, baseline, stress, amusement = compute_features(e4_data_dict, subject.labels, norm_type)\n",
    "\n",
    "    baseline_samples = get_samples(baseline, 1)\n",
    "    stress_samples = get_samples(stress, 2)\n",
    "    amusement_samples = get_samples(amusement, 0)\n",
    "\n",
    "    all_samples = pd.concat([baseline_samples, stress_samples, amusement_samples])\n",
    "    all_samples = pd.concat([all_samples.drop('label', axis=1), pd.get_dummies(all_samples['label'])], axis=1)\n",
    "    # Selected Features\n",
    "    # all_samples = all_samples[['EDA_mean', 'EDA_std', 'EDA_min', 'EDA_max',\n",
    "    #                          'BVP_mean', 'BVP_std', 'BVP_min', 'BVP_max',\n",
    "    #                        'TEMP_mean', 'TEMP_std', 'TEMP_min', 'TEMP_max',\n",
    "    #                        'net_acc_mean', 'net_acc_std', 'net_acc_min', 'net_acc_max',\n",
    "    #                        0, 1, 2]]\n",
    "    # Save file as csv (for now)\n",
    "    all_samples.to_csv(f'{OUTPUT_FOLDER}{subject_feature_path}/S{subject_id}_feats_4.csv')\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Last defined function is responsible for combining pre-processed data of all subjects into one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_files(subjects):\n",
    "    df_list = []\n",
    "    for s in subjects:\n",
    "        df = pd.read_csv(f'{OUTPUT_FOLDER}{subject_feature_path}/S{s}_feats_4.csv', index_col=0)\n",
    "        df['subject'] = s\n",
    "        df_list.append(df)\n",
    "\n",
    "    df = pd.concat(df_list)\n",
    "\n",
    "    df['label'] = (df['0'].astype(str) + df['1'].astype(str) + df['2'].astype(str)).apply(lambda x: x.index('1'))\n",
    "    df.drop(['0', '1', '2'], axis=1, inplace=True)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df.to_csv(f'{OUTPUT_FOLDER}/combined_subjects.csv')\n",
    "\n",
    "    counts = df['label'].value_counts()\n",
    "    print('Number of samples per class:')\n",
    "    for label, number in zip(counts.index, counts.values):\n",
    "        print(f'{int_to_label[label]}: {number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Pre-processing\n",
       "In this step, we go through all 15 subjects and create .csv files with pre-processed data per each subject and one .csv file with combined data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%jmd\n",
    "\n",
    "# Pre-processing\n",
    "In this step, we go through all 15 subjects and create .csv files with pre-processed data per each subject and one .csv file with combined data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for S2...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2093e+04 -1.2039e+04  5e+04  2e+02  2e-01\n",
      " 1: -1.2093e+04 -2.0218e+04  1e+04  4e+01  5e-02\n",
      " 2: -1.2100e+04 -1.5246e+04  3e+03  1e+01  1e-02\n",
      " 3: -1.2100e+04 -1.3551e+04  1e+03  4e+00  5e-03\n",
      " 4: -1.2097e+04 -1.2876e+04  8e+02  2e+00  2e-03\n",
      " 5: -1.2092e+04 -1.2599e+04  5e+02  8e-01  1e-03\n",
      " 6: -1.2089e+04 -1.2320e+04  2e+02  3e-01  4e-04\n",
      " 7: -1.2102e+04 -1.2158e+04  6e+01  2e-02  3e-05\n",
      " 8: -1.2127e+04 -1.2148e+04  2e+01  6e-03  8e-06\n",
      " 9: -1.2137e+04 -1.2146e+04  9e+00  2e-03  2e-06\n",
      "10: -1.2142e+04 -1.2146e+04  4e+00  5e-04  6e-07\n",
      "11: -1.2144e+04 -1.2145e+04  1e+00  1e-04  2e-07\n",
      "12: -1.2145e+04 -1.2145e+04  5e-01  2e-05  3e-08\n",
      "13: -1.2145e+04 -1.2145e+04  2e-01  5e-06  6e-09\n",
      "14: -1.2145e+04 -1.2145e+04  7e-02  1e-06  2e-09\n",
      "15: -1.2145e+04 -1.2145e+04  2e-02  3e-07  3e-10\n",
      "16: -1.2145e+04 -1.2145e+04  5e-03  3e-08  4e-11\n",
      "17: -1.2145e+04 -1.2145e+04  2e-03  6e-09  8e-12\n",
      "18: -1.2145e+04 -1.2145e+04  4e-04  7e-10  9e-13\n",
      "19: -1.2145e+04 -1.2145e+04  1e-04  2e-10  2e-13\n",
      "20: -1.2145e+04 -1.2145e+04  3e-05  2e-11  4e-14\n",
      "21: -1.2145e+04 -1.2145e+04  5e-06  4e-12  2e-14\n",
      "Optimal solution found.\n",
      "Processing data for S3...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2964e+04 -1.2924e+04  5e+04  2e+02  2e-01\n",
      " 1: -1.2950e+04 -1.7544e+04  5e+03  2e+01  2e-02\n",
      " 2: -1.2952e+04 -1.3618e+04  7e+02  3e+00  2e-03\n",
      " 3: -1.2951e+04 -1.3155e+04  2e+02  7e-01  5e-04\n",
      " 4: -1.2953e+04 -1.3016e+04  6e+01  1e-01  1e-04\n",
      " 5: -1.2971e+04 -1.2985e+04  1e+01  2e-02  1e-05\n",
      " 6: -1.2978e+04 -1.2983e+04  6e+00  5e-03  4e-06\n",
      " 7: -1.2981e+04 -1.2983e+04  2e+00  1e-03  1e-06\n",
      " 8: -1.2982e+04 -1.2983e+04  9e-01  3e-04  2e-07\n",
      " 9: -1.2983e+04 -1.2983e+04  3e-01  8e-05  6e-08\n",
      "10: -1.2983e+04 -1.2983e+04  2e-01  3e-05  2e-08\n",
      "11: -1.2983e+04 -1.2983e+04  5e-02  5e-06  3e-09\n",
      "12: -1.2983e+04 -1.2983e+04  1e-02  8e-07  6e-10\n",
      "13: -1.2983e+04 -1.2983e+04  4e-03  9e-08  6e-11\n",
      "14: -1.2983e+04 -1.2983e+04  9e-04  1e-08  8e-12\n",
      "15: -1.2983e+04 -1.2983e+04  4e-04  3e-09  2e-12\n",
      "16: -1.2983e+04 -1.2983e+04  1e-04  5e-10  4e-13\n",
      "17: -1.2983e+04 -1.2983e+04  3e-05  6e-11  4e-14\n",
      "18: -1.2983e+04 -1.2983e+04  6e-06  6e-12  9e-15\n",
      "Optimal solution found.\n",
      "Processing data for S4...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2830e+04 -1.2793e+04  4e+04  2e+02  3e-01\n",
      " 1: -1.2816e+04 -1.6600e+04  4e+03  2e+01  3e-02\n",
      " 2: -1.2817e+04 -1.3561e+04  8e+02  3e+00  5e-03\n",
      " 3: -1.2817e+04 -1.2933e+04  1e+02  4e-01  6e-04\n",
      " 4: -1.2826e+04 -1.2845e+04  2e+01  8e-03  1e-05\n",
      " 5: -1.2839e+04 -1.2844e+04  5e+00  2e-03  3e-06\n",
      " 6: -1.2841e+04 -1.2844e+04  3e+00  9e-04  1e-06\n",
      " 7: -1.2842e+04 -1.2844e+04  1e+00  1e-04  2e-07\n",
      " 8: -1.2843e+04 -1.2844e+04  3e-01  1e-05  2e-08\n",
      " 9: -1.2844e+04 -1.2844e+04  1e-01  3e-06  4e-09\n",
      "10: -1.2844e+04 -1.2844e+04  4e-02  6e-07  9e-10\n",
      "11: -1.2844e+04 -1.2844e+04  1e-02  1e-07  2e-10\n",
      "12: -1.2844e+04 -1.2844e+04  4e-03  2e-08  4e-11\n",
      "13: -1.2844e+04 -1.2844e+04  1e-03  3e-09  5e-12\n",
      "14: -1.2844e+04 -1.2844e+04  3e-04  3e-10  5e-13\n",
      "15: -1.2844e+04 -1.2844e+04  7e-05  3e-11  4e-14\n",
      "16: -1.2844e+04 -1.2844e+04  1e-05  3e-12  6e-15\n",
      "17: -1.2844e+04 -1.2844e+04  2e-06  3e-13  6e-15\n",
      "Optimal solution found.\n",
      "Processing data for S5...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.2499e+04 -1.2466e+04  4e+04  2e+02  3e-01\n",
      " 1: -1.2482e+04 -1.6534e+04  5e+03  2e+01  3e-02\n",
      " 2: -1.2479e+04 -1.3598e+04  1e+03  5e+00  6e-03\n",
      " 3: -1.2475e+04 -1.2826e+04  4e+02  1e+00  1e-03\n",
      " 4: -1.2476e+04 -1.2567e+04  9e+01  2e-01  3e-04\n",
      " 5: -1.2495e+04 -1.2516e+04  2e+01  3e-02  3e-05\n",
      " 6: -1.2499e+04 -1.2514e+04  2e+01  1e-02  2e-05\n",
      " 7: -1.2506e+04 -1.2513e+04  7e+00  5e-03  6e-06\n",
      " 8: -1.2510e+04 -1.2512e+04  2e+00  8e-04  1e-06\n",
      " 9: -1.2511e+04 -1.2512e+04  9e-01  2e-04  3e-07\n",
      "10: -1.2511e+04 -1.2512e+04  3e-01  1e-05  1e-08\n",
      "11: -1.2511e+04 -1.2512e+04  1e-01  4e-06  4e-09\n",
      "12: -1.2512e+04 -1.2512e+04  4e-02  6e-07  8e-10\n",
      "13: -1.2512e+04 -1.2512e+04  1e-02  1e-07  2e-10\n",
      "14: -1.2512e+04 -1.2512e+04  3e-03  2e-08  2e-11\n",
      "15: -1.2512e+04 -1.2512e+04  9e-04  2e-09  2e-12\n",
      "16: -1.2512e+04 -1.2512e+04  2e-04  2e-10  3e-13\n",
      "17: -1.2512e+04 -1.2512e+04  6e-05  3e-11  4e-14\n",
      "18: -1.2512e+04 -1.2512e+04  1e-05  4e-12  6e-15\n",
      "Optimal solution found.\n",
      "Processing data for S6...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.4123e+04 -1.4083e+04  4e+04  2e+02  4e-01\n",
      " 1: -1.4107e+04 -1.6974e+04  3e+03  1e+01  3e-02\n",
      " 2: -1.4110e+04 -1.4623e+04  5e+02  2e+00  4e-03\n",
      " 3: -1.4110e+04 -1.4246e+04  1e+02  5e-01  9e-04\n",
      " 4: -1.4114e+04 -1.4152e+04  4e+01  6e-02  1e-04\n",
      " 5: -1.4129e+04 -1.4140e+04  1e+01  2e-02  4e-05\n",
      " 6: -1.4134e+04 -1.4138e+04  4e+00  4e-03  8e-06\n",
      " 7: -1.4136e+04 -1.4138e+04  2e+00  1e-03  2e-06\n",
      " 8: -1.4137e+04 -1.4138e+04  6e-01  2e-04  5e-07\n",
      " 9: -1.4137e+04 -1.4138e+04  2e-01  5e-05  1e-07\n",
      "10: -1.4137e+04 -1.4138e+04  6e-02  1e-05  2e-08\n",
      "11: -1.4138e+04 -1.4138e+04  2e-02  2e-06  4e-09\n",
      "12: -1.4138e+04 -1.4138e+04  4e-03  4e-07  7e-10\n",
      "13: -1.4138e+04 -1.4138e+04  1e-03  5e-08  1e-10\n",
      "14: -1.4138e+04 -1.4138e+04  4e-04  9e-09  2e-11\n",
      "15: -1.4138e+04 -1.4138e+04  8e-05  7e-10  1e-12\n",
      "16: -1.4138e+04 -1.4138e+04  2e-05  6e-11  1e-13\n",
      "17: -1.4138e+04 -1.4138e+04  3e-06  7e-12  2e-14\n",
      "Optimal solution found.\n",
      "Processing data for S7...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0439e+04 -1.0404e+04  4e+04  2e+02  3e-01\n",
      " 1: -1.0433e+04 -1.5011e+04  5e+03  2e+01  3e-02\n",
      " 2: -1.0438e+04 -1.1584e+04  1e+03  5e+00  7e-03\n",
      " 3: -1.0438e+04 -1.0869e+04  4e+02  1e+00  2e-03\n",
      " 4: -1.0437e+04 -1.0621e+04  2e+02  4e-01  6e-04\n",
      " 5: -1.0438e+04 -1.0519e+04  8e+01  1e-01  2e-04\n",
      " 6: -1.0453e+04 -1.0470e+04  2e+01  1e-03  2e-06\n",
      " 7: -1.0462e+04 -1.0469e+04  7e+00  4e-04  6e-07\n",
      " 8: -1.0464e+04 -1.0468e+04  4e+00  1e-04  2e-07\n",
      " 9: -1.0466e+04 -1.0468e+04  2e+00  4e-05  6e-08\n",
      "10: -1.0467e+04 -1.0468e+04  7e-01  1e-05  2e-08\n",
      "11: -1.0468e+04 -1.0468e+04  3e-01  1e-06  2e-09\n",
      "12: -1.0468e+04 -1.0468e+04  7e-02  3e-07  4e-10\n",
      "13: -1.0468e+04 -1.0468e+04  2e-02  5e-08  7e-11\n",
      "14: -1.0468e+04 -1.0468e+04  7e-03  1e-08  1e-11\n",
      "15: -1.0468e+04 -1.0468e+04  2e-03  2e-09  3e-12\n",
      "16: -1.0468e+04 -1.0468e+04  5e-04  2e-10  3e-13\n",
      "17: -1.0468e+04 -1.0468e+04  1e-04  3e-11  5e-14\n",
      "18: -1.0468e+04 -1.0468e+04  2e-05  5e-12  1e-14\n",
      "19: -1.0468e+04 -1.0468e+04  3e-06  7e-13  9e-15\n",
      "Optimal solution found.\n",
      "Processing data for S8...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0912e+04 -1.0882e+04  3e+04  2e+02  3e-01\n",
      " 1: -1.0902e+04 -1.4201e+04  4e+03  2e+01  4e-02\n",
      " 2: -1.0902e+04 -1.1651e+04  8e+02  3e+00  7e-03\n",
      " 3: -1.0900e+04 -1.1152e+04  3e+02  9e-01  2e-03\n",
      " 4: -1.0899e+04 -1.1013e+04  1e+02  3e-01  6e-04\n",
      " 5: -1.0903e+04 -1.0936e+04  3e+01  3e-02  7e-05\n",
      " 6: -1.0918e+04 -1.0929e+04  1e+01  1e-02  2e-05\n",
      " 7: -1.0923e+04 -1.0927e+04  4e+00  9e-04  2e-06\n",
      " 8: -1.0926e+04 -1.0927e+04  2e+00  2e-04  5e-07\n",
      " 9: -1.0926e+04 -1.0927e+04  6e-01  7e-05  1e-07\n",
      "10: -1.0927e+04 -1.0927e+04  2e-01  3e-05  5e-08\n",
      "11: -1.0927e+04 -1.0927e+04  7e-02  5e-06  1e-08\n",
      "12: -1.0927e+04 -1.0927e+04  2e-02  7e-07  1e-09\n",
      "13: -1.0927e+04 -1.0927e+04  6e-03  1e-07  3e-10\n",
      "14: -1.0927e+04 -1.0927e+04  2e-03  2e-08  5e-11\n",
      "15: -1.0927e+04 -1.0927e+04  4e-04  4e-09  8e-12\n",
      "16: -1.0927e+04 -1.0927e+04  8e-05  7e-10  1e-12\n",
      "17: -1.0927e+04 -1.0927e+04  2e-05  1e-10  2e-13\n",
      "18: -1.0927e+04 -1.0927e+04  4e-06  2e-11  5e-14\n",
      "Optimal solution found.\n",
      "Processing data for S9...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0399e+04 -1.0355e+04  5e+04  2e+02  5e-01\n",
      " 1: -1.0395e+04 -1.8100e+04  1e+04  4e+01  1e-01\n",
      " 2: -1.0399e+04 -1.3142e+04  3e+03  9e+00  2e-02\n",
      " 3: -1.0399e+04 -1.1927e+04  2e+03  4e+00  1e-02\n",
      " 4: -1.0394e+04 -1.1311e+04  9e+02  2e+00  5e-03\n",
      " 5: -1.0385e+04 -1.0823e+04  4e+02  7e-01  2e-03\n",
      " 6: -1.0388e+04 -1.0540e+04  2e+02  2e-01  5e-04\n",
      " 7: -1.0412e+04 -1.0442e+04  3e+01  1e-02  3e-05\n",
      " 8: -1.0426e+04 -1.0439e+04  1e+01  4e-03  1e-05\n",
      " 9: -1.0433e+04 -1.0438e+04  6e+00  9e-04  2e-06\n",
      "10: -1.0436e+04 -1.0438e+04  2e+00  2e-05  6e-08\n",
      "11: -1.0437e+04 -1.0438e+04  9e-01  9e-06  2e-08\n",
      "12: -1.0437e+04 -1.0438e+04  4e-01  2e-06  4e-09\n",
      "13: -1.0437e+04 -1.0437e+04  2e-01  6e-07  2e-09\n",
      "14: -1.0437e+04 -1.0437e+04  5e-02  8e-08  2e-10\n",
      "15: -1.0437e+04 -1.0437e+04  1e-02  1e-08  3e-11\n",
      "16: -1.0437e+04 -1.0437e+04  4e-03  3e-09  6e-12\n",
      "17: -1.0437e+04 -1.0437e+04  1e-03  4e-10  1e-12\n",
      "18: -1.0437e+04 -1.0437e+04  3e-04  7e-11  2e-13\n",
      "19: -1.0437e+04 -1.0437e+04  6e-05  7e-12  2e-14\n",
      "20: -1.0437e+04 -1.0437e+04  2e-05  9e-13  2e-14\n",
      "21: -1.0437e+04 -1.0437e+04  4e-06  5e-13  1e-14\n",
      "Optimal solution found.\n",
      "Processing data for S10...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0985e+04 -1.0958e+04  3e+04  2e+02  2e-01\n",
      " 1: -1.0969e+04 -1.4118e+04  4e+03  2e+01  2e-02\n",
      " 2: -1.0968e+04 -1.1518e+04  6e+02  3e+00  3e-03\n",
      " 3: -1.0966e+04 -1.1164e+04  2e+02  8e-01  8e-04\n",
      " 4: -1.0964e+04 -1.1036e+04  7e+01  2e-01  2e-04\n",
      " 5: -1.0978e+04 -1.0991e+04  1e+01  6e-03  6e-06\n",
      " 6: -1.0984e+04 -1.0990e+04  6e+00  2e-03  2e-06\n",
      " 7: -1.0987e+04 -1.0990e+04  2e+00  5e-04  5e-07\n",
      " 8: -1.0989e+04 -1.0990e+04  1e+00  2e-05  2e-08\n",
      " 9: -1.0989e+04 -1.0990e+04  5e-01  7e-06  7e-09\n",
      "10: -1.0990e+04 -1.0990e+04  2e-01  2e-06  2e-09\n",
      "11: -1.0990e+04 -1.0990e+04  5e-02  4e-07  4e-10\n",
      "12: -1.0990e+04 -1.0990e+04  1e-02  6e-08  5e-11\n",
      "13: -1.0990e+04 -1.0990e+04  5e-03  9e-09  8e-12\n",
      "14: -1.0990e+04 -1.0990e+04  1e-03  7e-10  7e-13\n",
      "15: -1.0990e+04 -1.0990e+04  3e-04  9e-11  8e-14\n",
      "16: -1.0990e+04 -1.0990e+04  6e-05  5e-12  5e-15\n",
      "17: -1.0990e+04 -1.0990e+04  1e-05  3e-13  8e-15\n",
      "Optimal solution found.\n",
      "Processing data for S11...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0432e+04 -1.0396e+04  4e+04  2e+02  3e-01\n",
      " 1: -1.0428e+04 -1.7259e+04  8e+03  3e+01  6e-02\n",
      " 2: -1.0428e+04 -1.1659e+04  1e+03  4e+00  7e-03\n",
      " 3: -1.0430e+04 -1.0766e+04  3e+02  9e-01  2e-03\n",
      " 4: -1.0430e+04 -1.0572e+04  1e+02  3e-01  6e-04\n",
      " 5: -1.0435e+04 -1.0482e+04  5e+01  7e-02  1e-04\n",
      " 6: -1.0451e+04 -1.0461e+04  1e+01  7e-03  1e-05\n",
      " 7: -1.0455e+04 -1.0460e+04  5e+00  2e-03  4e-06\n",
      " 8: -1.0458e+04 -1.0460e+04  2e+00  7e-04  1e-06\n",
      " 9: -1.0459e+04 -1.0459e+04  9e-01  2e-04  3e-07\n",
      "10: -1.0459e+04 -1.0459e+04  3e-01  5e-05  9e-08\n",
      "11: -1.0459e+04 -1.0459e+04  1e-01  9e-06  2e-08\n",
      "12: -1.0459e+04 -1.0459e+04  4e-02  1e-06  3e-09\n",
      "13: -1.0459e+04 -1.0459e+04  1e-02  3e-07  6e-10\n",
      "14: -1.0459e+04 -1.0459e+04  3e-03  7e-08  1e-10\n",
      "15: -1.0459e+04 -1.0459e+04  9e-04  1e-08  2e-11\n",
      "16: -1.0459e+04 -1.0459e+04  2e-04  2e-09  3e-12\n",
      "17: -1.0459e+04 -1.0459e+04  6e-05  1e-10  2e-13\n",
      "18: -1.0459e+04 -1.0459e+04  1e-05  2e-11  3e-14\n",
      "19: -1.0459e+04 -1.0459e+04  2e-06  2e-12  1e-14\n",
      "Optimal solution found.\n",
      "Processing data for S13...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1061e+04 -1.1035e+04  3e+04  2e+02  2e-01\n",
      " 1: -1.1047e+04 -1.3149e+04  2e+03  1e+01  2e-02\n",
      " 2: -1.1048e+04 -1.1543e+04  5e+02  2e+00  3e-03\n",
      " 3: -1.1046e+04 -1.1205e+04  2e+02  6e-01  8e-04\n",
      " 4: -1.1050e+04 -1.1094e+04  4e+01  1e-01  2e-04\n",
      " 5: -1.1060e+04 -1.1074e+04  1e+01  3e-02  3e-05\n",
      " 6: -1.1067e+04 -1.1071e+04  4e+00  3e-03  4e-06\n",
      " 7: -1.1069e+04 -1.1070e+04  2e+00  1e-03  1e-06\n",
      " 8: -1.1070e+04 -1.1070e+04  7e-01  3e-04  4e-07\n",
      " 9: -1.1070e+04 -1.1070e+04  2e-01  6e-05  8e-08\n",
      "10: -1.1070e+04 -1.1070e+04  7e-02  1e-05  2e-08\n",
      "11: -1.1070e+04 -1.1070e+04  2e-02  4e-06  5e-09\n",
      "12: -1.1070e+04 -1.1070e+04  7e-03  4e-07  5e-10\n",
      "13: -1.1070e+04 -1.1070e+04  2e-03  7e-08  9e-11\n",
      "14: -1.1070e+04 -1.1070e+04  5e-04  6e-09  7e-12\n",
      "15: -1.1070e+04 -1.1070e+04  1e-04  7e-10  9e-13\n",
      "16: -1.1070e+04 -1.1070e+04  4e-05  1e-10  1e-13\n",
      "17: -1.1070e+04 -1.1070e+04  7e-06  1e-11  2e-14\n",
      "Optimal solution found.\n",
      "Processing data for S14...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0060e+04 -9.7085e+03  3e+05  4e+02  1e+00\n",
      " 1: -1.0360e+04 -8.1064e+04  8e+04  9e+01  2e-01\n",
      " 2: -1.0520e+04 -5.1233e+04  4e+04  4e+01  8e-02\n",
      " 3: -1.0566e+04 -4.8090e+04  4e+04  3e+01  7e-02\n",
      " 4: -1.0649e+04 -3.3207e+04  2e+04  2e+01  4e-02\n",
      " 5: -1.0687e+04 -3.0838e+04  2e+04  1e+01  3e-02\n",
      " 6: -1.0738e+04 -2.2961e+04  1e+04  7e+00  2e-02\n",
      " 7: -1.0752e+04 -2.2157e+04  1e+04  5e+00  1e-02\n",
      " 8: -1.0786e+04 -1.6585e+04  6e+03  3e+00  6e-03\n",
      " 9: -1.0780e+04 -1.5228e+04  4e+03  1e+00  3e-03\n",
      "10: -1.0786e+04 -1.1924e+04  1e+03  3e-01  7e-04\n",
      "11: -1.0824e+04 -1.1018e+04  2e+02  2e-02  5e-05\n",
      "12: -1.0837e+04 -1.0992e+04  2e+02  1e-02  3e-05\n",
      "13: -1.0887e+04 -1.0957e+04  7e+01  5e-03  1e-05\n",
      "14: -1.0906e+04 -1.0948e+04  4e+01  2e-03  4e-06\n",
      "15: -1.0924e+04 -1.0943e+04  2e+01  3e-04  8e-07\n",
      "16: -1.0932e+04 -1.0940e+04  8e+00  8e-05  2e-07\n",
      "17: -1.0936e+04 -1.0939e+04  3e+00  2e-05  4e-08\n",
      "18: -1.0937e+04 -1.0938e+04  9e-01  3e-06  8e-09\n",
      "19: -1.0938e+04 -1.0938e+04  2e-01  5e-07  1e-09\n",
      "20: -1.0938e+04 -1.0938e+04  6e-02  8e-08  2e-10\n",
      "21: -1.0938e+04 -1.0938e+04  1e-02  1e-08  2e-11\n",
      "22: -1.0938e+04 -1.0938e+04  4e-03  2e-09  6e-12\n",
      "23: -1.0938e+04 -1.0938e+04  1e-03  5e-10  1e-12\n",
      "24: -1.0938e+04 -1.0938e+04  3e-04  6e-12  1e-13\n",
      "25: -1.0938e+04 -1.0938e+04  8e-05  3e-12  1e-13\n",
      "26: -1.0938e+04 -1.0938e+04  9e-06  3e-12  3e-13\n",
      "Optimal solution found.\n",
      "Processing data for S15...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0493e+04 -1.0468e+04  3e+04  2e+02  1e-01\n",
      " 1: -1.0480e+04 -1.2520e+04  2e+03  1e+01  1e-02\n",
      " 2: -1.0478e+04 -1.1053e+04  6e+02  3e+00  2e-03\n",
      " 3: -1.0476e+04 -1.0713e+04  2e+02  1e+00  8e-04\n",
      " 4: -1.0475e+04 -1.0561e+04  9e+01  3e-01  2e-04\n",
      " 5: -1.0486e+04 -1.0502e+04  2e+01  3e-03  2e-06\n",
      " 6: -1.0494e+04 -1.0502e+04  8e+00  1e-03  8e-07\n",
      " 7: -1.0498e+04 -1.0501e+04  3e+00  3e-04  2e-07\n",
      " 8: -1.0500e+04 -1.0501e+04  1e+00  5e-05  4e-08\n",
      " 9: -1.0500e+04 -1.0501e+04  4e-01  1e-05  1e-08\n",
      "10: -1.0501e+04 -1.0501e+04  2e-01  3e-06  2e-09\n",
      "11: -1.0501e+04 -1.0501e+04  5e-02  3e-07  3e-10\n",
      "12: -1.0501e+04 -1.0501e+04  2e-02  6e-08  5e-11\n",
      "13: -1.0501e+04 -1.0501e+04  5e-03  1e-08  1e-11\n",
      "14: -1.0501e+04 -1.0501e+04  1e-03  2e-09  2e-12\n",
      "15: -1.0501e+04 -1.0501e+04  3e-04  2e-10  2e-13\n",
      "16: -1.0501e+04 -1.0501e+04  7e-05  2e-11  2e-14\n",
      "17: -1.0501e+04 -1.0501e+04  1e-05  3e-12  4e-15\n",
      "18: -1.0501e+04 -1.0501e+04  3e-06  7e-13  2e-15\n",
      "Optimal solution found.\n",
      "Processing data for S16...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1256e+04 -1.1234e+04  3e+04  2e+02  3e-01\n",
      " 1: -1.1240e+04 -1.2874e+04  2e+03  1e+01  2e-02\n",
      " 2: -1.1238e+04 -1.1487e+04  3e+02  1e+00  3e-03\n",
      " 3: -1.1238e+04 -1.1297e+04  6e+01  2e-01  4e-04\n",
      " 4: -1.1247e+04 -1.1260e+04  1e+01  2e-03  4e-06\n",
      " 5: -1.1256e+04 -1.1260e+04  4e+00  5e-04  1e-06\n",
      " 6: -1.1258e+04 -1.1260e+04  2e+00  2e-04  4e-07\n",
      " 7: -1.1259e+04 -1.1260e+04  7e-01  4e-05  9e-08\n",
      " 8: -1.1259e+04 -1.1259e+04  2e-01  8e-06  2e-08\n",
      " 9: -1.1259e+04 -1.1259e+04  7e-02  2e-06  4e-09\n",
      "10: -1.1259e+04 -1.1259e+04  2e-02  4e-07  8e-10\n",
      "11: -1.1259e+04 -1.1259e+04  7e-03  7e-08  2e-10\n",
      "12: -1.1259e+04 -1.1259e+04  2e-03  1e-08  2e-11\n",
      "13: -1.1259e+04 -1.1259e+04  6e-04  1e-09  3e-12\n",
      "14: -1.1259e+04 -1.1259e+04  1e-04  2e-10  4e-13\n",
      "15: -1.1259e+04 -1.1259e+04  3e-05  2e-11  4e-14\n",
      "16: -1.1259e+04 -1.1259e+04  5e-06  3e-12  8e-15\n",
      "Optimal solution found.\n",
      "Processing data for S17...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1705e+04 -1.1627e+04  5e+04  2e+02  2e-01\n",
      " 1: -1.1726e+04 -2.1448e+04  1e+04  5e+01  4e-02\n",
      " 2: -1.1750e+04 -1.5450e+04  4e+03  1e+01  9e-03\n",
      " 3: -1.1762e+04 -1.3161e+04  1e+03  4e+00  3e-03\n",
      " 4: -1.1763e+04 -1.2937e+04  1e+03  3e+00  2e-03\n",
      " 5: -1.1768e+04 -1.2350e+04  6e+02  1e+00  1e-03\n",
      " 6: -1.1769e+04 -1.2078e+04  3e+02  5e-01  4e-04\n",
      " 7: -1.1774e+04 -1.1891e+04  1e+02  2e-01  1e-04\n",
      " 8: -1.1794e+04 -1.1820e+04  3e+01  2e-02  1e-05\n",
      " 9: -1.1805e+04 -1.1815e+04  1e+01  5e-03  4e-06\n",
      "10: -1.1809e+04 -1.1814e+04  4e+00  1e-03  9e-07\n",
      "11: -1.1811e+04 -1.1813e+04  2e+00  1e-04  1e-07\n",
      "12: -1.1812e+04 -1.1813e+04  6e-01  3e-05  2e-08\n",
      "13: -1.1812e+04 -1.1813e+04  2e-01  6e-06  5e-09\n",
      "14: -1.1812e+04 -1.1813e+04  8e-02  2e-06  1e-09\n",
      "15: -1.1812e+04 -1.1812e+04  2e-02  4e-07  3e-10\n",
      "16: -1.1812e+04 -1.1812e+04  7e-03  6e-08  5e-11\n",
      "17: -1.1812e+04 -1.1812e+04  2e-03  1e-08  9e-12\n",
      "18: -1.1812e+04 -1.1812e+04  4e-04  2e-09  2e-12\n",
      "19: -1.1812e+04 -1.1812e+04  2e-04  4e-10  4e-13\n",
      "20: -1.1812e+04 -1.1812e+04  3e-05  2e-11  4e-14\n",
      "21: -1.1812e+04 -1.1812e+04  8e-06  5e-12  2e-14\n",
      "Optimal solution found.\n",
      "Number of samples per class:\n",
      "baseline: 1135\n",
      "stress: 625\n",
      "amusement: 331\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# -.-|m { input_fold: show, output: false }\n",
    "\n",
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "\n",
    "for patient in subject_ids:\n",
    "    print(f'Processing data for S{patient}...')\n",
    "    make_patient_data(patient)\n",
    "\n",
    "combine_files(subject_ids)\n",
    "print('Processing complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# References\n",
       "[//]: # (-.-)\n",
       "\n",
       "1. [WESAD Dataset Research Paper](https://www.eti.uni-siegen.de/ubicomp/papers/ubi_icmi2018.pdf)\n",
       "2. [Preprocessing steps for the WESAD dataset](https://github.com/WJMatthew/WESAD)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%jmd\n",
    "# References\n",
    "[//]: # (-.-)\n",
    "\n",
    "1. [WESAD Dataset Research Paper](https://www.eti.uni-siegen.de/ubicomp/papers/ubi_icmi2018.pdf)\n",
    "2. [Preprocessing steps for the WESAD dataset](https://github.com/WJMatthew/WESAD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
